input {
	elasticsearch {
		hosts => "localhost"
		index => "muzo-cgs-smlouva"
		#query => '{ "query": { "query_string": { "query": "*" } } }'
		query => '{"query":{"match":{"version":"2"}},"sort":[{"_id":{"order":"asc"}}]}'
		size => 10000
		scroll => "5m"
		docinfo => true
	}
}

filter {
	ruby {
		init => "
			begin
				tday = Time.now.strftime('%Y-%m-%d')
				@@csv_stamp = tday
				@@csv_file    = '/var/ftp/pub/cgs-smlouvy_' + tday + '.csv'
				@@csv_headers = ['cislo_smlouvy', 'predmet', 'dodavatel', 'ico', 'datum_uzavreni', 'datum_trvani', 'celkova_castka', 'mena']
				if File.zero?(@@csv_file) || !File.exist?(@@csv_file)
			    	CSV.open(@@csv_file, 'w', {:col_sep => ','}) do |csv|
						csv << @@csv_headers
			    	end
				end
      		end
		"
		code => "
			begin
				event.set('[@metadata][csv_file]', @@csv_file)
        		event.set('[@metadata][csv_headers]', @@csv_headers)
        		event.set('[filepath]', @@csv_file)
        		event.set('[csvstamp]', @@csv_stamp)
				datearr1 = ['dateconclusion','datevalidity']
				datearr2 = ['dateconclusionStr','datevalidityStr']	    
				for i in 0..1
		    		event.set(datearr2.at(i), '')
		    		splitDate = ''
		    		if event.get(datearr1.at(i)) != nil
		      			tstamp = event.get(datearr1.at(i))
		       			event.set(datearr2.at(i), tstamp[0..9])
		    		end
				end
    		end
    	"
	}
	mutate {
		add_field => {
	  		"mena" => "CZK"
		}
		convert => { 
	    	"total" => "float"
		}
	}
}

output {
	csv {
		spreadsheet_safe => true
		fields => ["contractid", "title", "contractorcompany", "contractorid", "dateconclusionStr", "datevalidityStr", "total", "mena"]
		csv_options => {"col_sep" => ","}
		path => "/var/ftp/pub/cgs-smlouvy_%{csvstamp}.csv"
	}
	stdout {
		codec => dots
	}
}
